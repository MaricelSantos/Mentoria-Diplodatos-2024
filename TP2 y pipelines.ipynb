{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyNKMg2oGFYWModqIDA0RQzV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Importar Librerias"],"metadata":{"id":"vXNT_I-_tdHE"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"UiszfCUKtb0C","executionInfo":{"status":"ok","timestamp":1720616196189,"user_tz":180,"elapsed":3186,"user":{"displayName":"Maricel Santos","userId":"08622494968757391828"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.pipeline import Pipeline\n","from sklearn.preprocessing import StandardScaler, OneHotEncoder\n","from sklearn.compose import ColumnTransformer\n","from sklearn.impute import SimpleImputer\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, r2_score\n"]},{"cell_type":"markdown","source":["# Carga de los dataset"],"metadata":{"id":"IJKwwX9ptp3j"}},{"cell_type":"code","source":["df_21_23 = pd.read_csv('https://raw.githubusercontent.com/MaricelSantos/Mentoria-Diplodatos-2024/main/Conexiones_Transparentes_21-23.csv')\n","df_22_sys=  pd.read_csv('https://raw.githubusercontent.com/MaricelSantos/Mentoria-Diplodatos-2024/main/Conexiones_Transparentes.csv')"],"metadata":{"id":"H9XPuLvAts1S","executionInfo":{"status":"ok","timestamp":1720616406790,"user_tz":180,"elapsed":386,"user":{"displayName":"Maricel Santos","userId":"08622494968757391828"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# Eliminacion de filas y columnas\n","\n","De esto hablamos durante la última reunión. Definir criterios y aplicar el codigo necesario"],"metadata":{"id":"OWOf7ByOuKT0"}},{"cell_type":"markdown","source":["# Separación del data set\n","Se los muestro de forma generica. Pero como hablamos nuestra variable target seria ICA el indice de calidad de agua."],"metadata":{"id":"7AZcvFSBy4ra"}},{"cell_type":"code","source":["X = df.drop('target', axis=1)\n","y = df['target']\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"],"metadata":{"id":"4WBXpERozJc7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Definición de Columnas y Transformaciones\n","Es necesario identificar las columnas numéricas y categóricas porque vamos a tener diferentes transformaciones según cada tipo de columna.\n","\n","\n","numeric_transformer contiene un pipeline con dos pasos, imputar que utiliza el metodo SimpleImputer con la mediana como argumento y escalar que utiliza un estandar escalar. categorial_transformer hace lo propio con las categoricas y luego preprocessor agrupa los transformadores para las columnas. Hasta aca tenemos de forma ordenada los procedimientos para cada columna."],"metadata":{"id":"SKamcaYJu7xr"}},{"cell_type":"code","source":["numeric_features = ['num_col1', 'num_col2']\n","categorical_features = ['cat_col1', 'cat_col2']\n","\n","numeric_transformer = Pipeline(steps=[\n","    ('imputar', SimpleImputer(strategy='median')),\n","    ('scalar', StandardScaler())])\n","\n","categorical_transformer = Pipeline(steps=[\n","    ('imputar', SimpleImputer(strategy='constant', fill_value='missing')),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n","\n","preprocessor = ColumnTransformer(\n","    transformers=[\n","        ('num', numeric_transformer, numeric_features),\n","        ('cat', categorical_transformer, categorical_features)])\n"],"metadata":{"id":"RJ4JyTcovnGT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Definición de Modelos (TP3)\n","Esto es parte del TP3 pero se los muestro para que se entienda como se usa el pipeline. En este caso el ejemplo es con un Random Forest Regressor"],"metadata":{"id":"r2Td4zhM2Fop"}},{"cell_type":"code","source":["# Pipeline que incluye el preprocesamiento y el modelo RandomForestRegressor\n","pipeline = Pipeline(steps=[\n","    ('preprocessor', preprocessor),\n","    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))])\n"],"metadata":{"id":"1HwdRHYr2C6h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Utilización del pipeline"],"metadata":{"id":"4B7GKJ9d3l3S"}},{"cell_type":"code","source":["\n","#Entrenamiento\n","\n","pipeline.fit(X_train, y_train)\n","\n","#Predicción\n","\n","y_pred = pipeline.predict(X_test)\n","\n","#Metricas\n","\n","mse = mean_squared_error(y_test, y_pred)\n","r2 = r2_score(y_test, y_pred)\n","\n","print(f'Mean Squared Error: {mse}')\n","print(f'R^2 Score: {r2}')"],"metadata":{"id":"_AWbnJyG3rdl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Este ejemplo muestra cómo construir un pipeline para un problema de regresión utilizando RandomForestRegressor. Se pueden modificar las transformaciones, las estrategias de imputación y los hiperparámetros del modelo. En el TP3 va a ser necesario aplicar técnicas avanzadas como la búsqueda de hiperparámetros (GridSearchCV) o validación cruzada (cross-validation) en el modelo para optimizar aún más."],"metadata":{"id":"QZH1aeto4dd8"}},{"cell_type":"markdown","source":["# Curación y Creación de Múltiples Versiones del Dataset\n","\n","Vamos a ver el ejemplo de quitar outliers y comparar con un dataset donde no fueron removidos."],"metadata":{"id":"dptM0x235GTS"}},{"cell_type":"code","source":["def remove_outliers(df, columns):\n","    for col in columns:\n","        q1 = df[col].quantile(0.25)\n","        q3 = df[col].quantile(0.75)\n","        iqr = q3 - q1\n","        df = df[(df[col] >= (q1 - 1.5 * iqr)) & (df[col] <= (q3 + 1.5 * iqr))]\n","    return df\n","\n","#Generamos el df sin outliers\n","df_no_outliers = remove_outliers(df, numeric_features)\n","\n","#Separamos el df sin outliers\n","X_train_no_outliers, X_test_no_outliers, y_train_no_outliers, y_test_no_outliers = train_test_split(\n","    df_no_outliers.drop('target', axis=1), df_no_outliers['target'], test_size=0.2, random_state=42)"],"metadata":{"id":"a6EnwrOk5Emj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Uso del pipeline comparativamente"],"metadata":{"id":"u-iWklLk_u_y"}},{"cell_type":"code","source":["# Original Dataset\n","pipeline.fit(X_train, y_train)\n","y_pred = pipeline.predict(X_test)\n","mse = mean_squared_error(y_test, y_pred)\n","r2 = r2_score(y_test, y_pred)\n","print(f'Mean Squared Error: {mean_squared_error(y_test, y_pred)}')\n","print(f'R^2 Score: {r2_score(y_test, y_pred)}')\n","\n","\n","# No Outliers Dataset\n","pipeline.fit(X_train_no_outliers, y_train_no_outliers)\n","y_pred_no_outliers = pipeline.predict(X_test_no_outliers)\n","print(f'No Outliers Dataset- Mean Squared Error: {mean_squared_error(y_test_no_outliers, y_pred_no_outliers)}')\n","print(f'No Outliers Dataset - R^2 Score: {r2_score(y_test_no_outliers, y_pred_no_outliers)}')\n"],"metadata":{"id":"_A96qM-v5gfT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Lo que hace el pipeline es ahorrarnos bastante codigo y trabajar de una manera más limpia. Si no lo utilizamos un paso de normalización se vería así."],"metadata":{"id":"N1ePu89i6eHi"}},{"cell_type":"markdown","source":["#SIN PIPELINE"],"metadata":{"id":"DlV2gJw_CCJc"}},{"cell_type":"code","source":["#Defino el transformados que se va aplicar\n","scaler = StandardScaler()\n","\n","#Aplico transformador a las numericas del train del dataset origical\n","\n","X_train_normal = scaler.fit_transform(X_train[numeric_features])\n","\n","# El paso anterior devuelve un array por lo tanto es necesario volver a obtener panda df\n","df_normalizado_train = pd.DataFrame(X_train_normal, columns=X_train[numeric_features].columns)\n","\n","# En este paso se concatena lo obtenido con lo original o con lo que venga trabajando\n","# por ejemplo concatenar lo aplicado a las numericas con lo aplicado a las categoricas\n","X_train_normal_hotencoding = pd.concat([df_normalizado_train, df_hotencoding_train], axis=1)\n","\n","#Repito los pasos con el test pero con el cuidado de que aquí no utilizo fit_transform\n","#solo transform porque se trata de test\n","\n","X_test_normal = scaler.transform(X_test[numeric_features])\n","df_normalizado_test = pd.DataFrame(X_test_normal, columns=X_test[numeric_features].columns)\n","X_test_normal_hotencoding = pd.concat([df_normalizado_test, df_hotencoding_test], axis=1)\n","\n","\n","# Aplicación de un modelo\n","# Crear una instancia de RandomForestRegressor\n","regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n","regressor.fit(X_train, y_train)\n","y_pred = regressor.predict(X_test)\n","mse = mean_squared_error(y_test, y_pred)\n","r2 = r2_score(y_test, y_pred)\n","print(f'Mean Squared Error: {mean_squared_error(y_test, y_pred)}')\n","print(f'R^2 Score: {r2_score(y_test, y_pred)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"Bbd7C-gT6xmt","executionInfo":{"status":"error","timestamp":1720620769891,"user_tz":180,"elapsed":1055,"user":{"displayName":"Maricel Santos","userId":"08622494968757391828"}},"outputId":"ce51ea29-055a-491d-b739-00540b6f2644"},"execution_count":4,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'X_train' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-5687174a8a1c>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#Aplico transformador a las numericas del train del dataset origical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train_normal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnumeric_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# El paso anterior devuelve un array por lo tanto es necesario volver a obtener panda df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"]}]},{"cell_type":"markdown","source":["El bloque anterior solo esta hecho para el dataset original. Si quiero comparar con el dataset sin outliers tengo que definir un bloque similar pero con las variables correspondientes a ese dataset. Luego puedo aplicar el modelo sobre los train y predecir sobre los test para comparar metricas.\n","Durante el cursado se ve el uso de transformadores de esta manera y no se ve pipelines por lo tanto es una decisión de ustedes que herramienta utilizar. Ambas son correctas"],"metadata":{"id":"-z9YHouT_d5q"}}]}